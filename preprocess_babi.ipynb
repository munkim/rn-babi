{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "babi_dir = '/home/mjc/datasets/babi/tasks_1-20_v1-2/en-10k/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_list = [babi_dir+file_name for file_name in os.listdir(babi_dir) \n",
    "              if 'train.txt' in file_name]\n",
    "test_list = [babi_dir+file_name for file_name in os.listdir(babi_dir) \n",
    "              if 'test.txt' in file_name]\n",
    "val_list = [babi_dir+file_name for file_name in os.listdir(babi_dir) \n",
    "              if 'val.txt' in file_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess_line(line):\n",
    "    line = line.replace('.','')\n",
    "    line = line.replace('?','')\n",
    "    line = line.strip()\n",
    "    return line\n",
    "\n",
    "def line2idx(line, w2i):\n",
    "    line = line.split(\" \")\n",
    "    return [str(w2i[word]) for word in line]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get collection of input data\n",
    "out = []\n",
    "sample = train_list[0]\n",
    "for train_file in train_list:\n",
    "    with open(train_file) as f:\n",
    "        lines = f.read()\n",
    "        lines = re.sub(r'\\d+','',lines)\n",
    "        lines = lines.split('\\n')\n",
    "#         lines = f.readlines()\n",
    "        q_idx = [i for i,line in enumerate(lines) if '?' in line]\n",
    "        for idx in q_idx:\n",
    "            prev_lines = [preprocess_line(line.lower()) for line in lines[max(0,idx-30):idx]\n",
    "                         if '?' not in line]\n",
    "            prev_lines = prev_lines[-20:]\n",
    "            line = lines[idx].split('\\t')\n",
    "            query = preprocess_line(line[0].lower())\n",
    "            answer = line[1].lower()\n",
    "            out.append((prev_lines,query,answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get collection of input data\n",
    "out = []\n",
    "sample = test_list[0]\n",
    "for test_file in test_list:\n",
    "    with open(test_file) as f:\n",
    "        lines = f.read()\n",
    "        lines = re.sub(r'\\d+','',lines)\n",
    "        lines = lines.split('\\n')\n",
    "#         lines = f.readlines()\n",
    "        q_idx = [i for i,line in enumerate(lines) if '?' in line]\n",
    "        for idx in q_idx:\n",
    "            prev_lines = [preprocess_line(line.lower()) for line in lines[max(0,idx-30):idx]\n",
    "                         if '?' not in line]\n",
    "            prev_lines = prev_lines[-20:]\n",
    "            line = lines[idx].split('\\t')\n",
    "            query = preprocess_line(line[0].lower())\n",
    "            answer = line[1].lower()\n",
    "            out.append((prev_lines,query,answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get vocabulary\n",
    "word_list = []\n",
    "for train_file in train_list:\n",
    "    with open(train_file) as f:\n",
    "        text = f.read()\n",
    "        text = text.lower()\n",
    "        text = text.replace(\".\",\"\")\n",
    "        text = text.replace(\"?\",\" \")\n",
    "        text = text.replace(\"\\n\",\" \")\n",
    "        text = text.replace(\"\\t\",\" \")\n",
    "        text = text.split(\" \")\n",
    "        word_list.extend(text)\n",
    "\n",
    "# get unique words of dataset\n",
    "vocab_list = list(set(word_list))\n",
    "vocab_list = vocab_list[1:] # to remove \" \"\n",
    "vocab_list = [x for x in vocab_list if x.isnumeric()==False]\n",
    "\n",
    "# create w2i and i2w\n",
    "word2idx = {word:i for i,word in enumerate(vocab_list)}\n",
    "idx2word = {i:word for i,word in enumerate(vocab_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2idx = np.load(file='word2idx.npy').item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['mary is in the school', 'bill is in the kitchen'],\n",
       " 'is bill in the bedroom',\n",
       " 'no')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 146,\n",
       " 'above': 84,\n",
       " 'afraid': 69,\n",
       " 'after': 17,\n",
       " 'afternoon': 49,\n",
       " 'afterwards': 83,\n",
       " 'and': 140,\n",
       " 'antoine': 104,\n",
       " 'apple': 70,\n",
       " 'apple,football': 76,\n",
       " 'apple,football,milk': 39,\n",
       " 'apple,milk': 113,\n",
       " 'apple,milk,football': 44,\n",
       " 'are': 149,\n",
       " 'back': 20,\n",
       " 'bathroom': 14,\n",
       " 'bedroom': 161,\n",
       " 'before': 170,\n",
       " 'below': 141,\n",
       " 'bernhard': 143,\n",
       " 'bigger': 100,\n",
       " 'bill': 91,\n",
       " 'blue': 8,\n",
       " 'bored': 116,\n",
       " 'box': 169,\n",
       " 'brian': 148,\n",
       " 'carrying': 162,\n",
       " 'cat': 10,\n",
       " 'cats': 46,\n",
       " 'chest': 13,\n",
       " 'chocolate': 74,\n",
       " 'chocolates': 1,\n",
       " 'cinema': 167,\n",
       " 'color': 15,\n",
       " 'container': 2,\n",
       " 'daniel': 95,\n",
       " 'did': 175,\n",
       " 'discarded': 4,\n",
       " 'do': 118,\n",
       " 'does': 105,\n",
       " 'down': 43,\n",
       " 'dropped': 53,\n",
       " 'e,e': 101,\n",
       " 'e,n': 129,\n",
       " 'e,s': 145,\n",
       " 'east': 119,\n",
       " 'either': 9,\n",
       " 'emily': 122,\n",
       " 'evening': 57,\n",
       " 'fit': 56,\n",
       " 'fits': 147,\n",
       " 'following': 23,\n",
       " 'football': 26,\n",
       " 'football,apple': 31,\n",
       " 'football,apple,milk': 77,\n",
       " 'football,milk': 128,\n",
       " 'football,milk,apple': 126,\n",
       " 'fred': 11,\n",
       " 'frog': 156,\n",
       " 'from': 152,\n",
       " 'garden': 90,\n",
       " 'gave': 136,\n",
       " 'gertrude': 55,\n",
       " 'get': 47,\n",
       " 'give': 63,\n",
       " 'go': 59,\n",
       " 'got': 154,\n",
       " 'grabbed': 65,\n",
       " 'gray': 32,\n",
       " 'green': 134,\n",
       " 'greg': 45,\n",
       " 'hallway': 88,\n",
       " 'handed': 150,\n",
       " 'he': 159,\n",
       " 'how': 19,\n",
       " 'hungry': 41,\n",
       " 'in': 3,\n",
       " 'inside': 163,\n",
       " 'is': 5,\n",
       " 'jason': 12,\n",
       " 'jeff': 130,\n",
       " 'jessica': 174,\n",
       " 'john': 166,\n",
       " 'journeyed': 28,\n",
       " 'julie': 50,\n",
       " 'julius': 81,\n",
       " 'kitchen': 97,\n",
       " 'left': 132,\n",
       " 'lily': 54,\n",
       " 'lion': 160,\n",
       " 'longer': 36,\n",
       " 'many': 34,\n",
       " 'mary': 102,\n",
       " 'maybe': 6,\n",
       " 'mice': 164,\n",
       " 'milk': 144,\n",
       " 'milk,apple': 120,\n",
       " 'milk,apple,football': 78,\n",
       " 'milk,football': 138,\n",
       " 'milk,football,apple': 64,\n",
       " 'morning': 94,\n",
       " 'mouse': 33,\n",
       " 'moved': 99,\n",
       " 'n,e': 96,\n",
       " 'n,n': 151,\n",
       " 'n,w': 75,\n",
       " 'no': 37,\n",
       " 'none': 112,\n",
       " 'north': 22,\n",
       " 'not': 86,\n",
       " 'nothing': 106,\n",
       " 'objects': 168,\n",
       " 'of': 171,\n",
       " 'office': 62,\n",
       " 'one': 18,\n",
       " 'or': 85,\n",
       " 'pajamas': 123,\n",
       " 'park': 30,\n",
       " 'passed': 16,\n",
       " 'picked': 98,\n",
       " 'pink': 93,\n",
       " 'put': 103,\n",
       " 'received': 48,\n",
       " 'rectangle': 153,\n",
       " 'red': 165,\n",
       " 'rhino': 60,\n",
       " 'right': 29,\n",
       " 's,e': 0,\n",
       " 's,s': 92,\n",
       " 's,w': 114,\n",
       " 'sandra': 127,\n",
       " 'school': 139,\n",
       " 'she': 173,\n",
       " 'sheep': 142,\n",
       " 'south': 135,\n",
       " 'sphere': 42,\n",
       " 'square': 40,\n",
       " 'suitcase': 109,\n",
       " 'sumit': 158,\n",
       " 'swan': 66,\n",
       " 'than': 89,\n",
       " 'that': 87,\n",
       " 'the': 155,\n",
       " 'then': 68,\n",
       " 'there': 115,\n",
       " 'they': 79,\n",
       " 'thirsty': 51,\n",
       " 'this': 172,\n",
       " 'three': 25,\n",
       " 'tired': 73,\n",
       " 'to': 107,\n",
       " 'took': 121,\n",
       " 'travelled': 7,\n",
       " 'triangle': 82,\n",
       " 'two': 137,\n",
       " 'up': 21,\n",
       " 'w,n': 117,\n",
       " 'w,s': 133,\n",
       " 'w,w': 35,\n",
       " 'was': 80,\n",
       " 'went': 72,\n",
       " 'west': 108,\n",
       " 'what': 61,\n",
       " 'where': 111,\n",
       " 'white': 27,\n",
       " 'who': 124,\n",
       " 'why': 110,\n",
       " 'will': 58,\n",
       " 'winona': 131,\n",
       " 'wolf': 157,\n",
       " 'wolves': 24,\n",
       " 'yann': 67,\n",
       " 'yellow': 52,\n",
       " 'yes': 71,\n",
       " 'yesterday': 125,\n",
       " 'you': 38}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# change out list to number indices\n",
    "out2 = []\n",
    "for lines, query, answer in out:\n",
    "    lines2 = '\\t'.join([' '.join(line2idx(line, word2idx)) for line in lines])\n",
    "    query2 = ' '.join(line2idx(query, word2idx))\n",
    "    answer2 = line2idx(answer, word2idx)[0]\n",
    "    out2.append('::'.join([lines2,query2,answer2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('out2.txt','w') as f:\n",
    "    f.write('\\n'.join(out2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('out2_temp.txt','w') as f:\n",
    "    f.write('\\n'.join(out2[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('out2_temp.txt','r') as f:\n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# np.save('word2idx.npy', word2idx)\n",
    "# np.save('idx2word.npy', idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
